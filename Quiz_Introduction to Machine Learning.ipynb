{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Komal93singh/Interview-Question-ML/blob/main/Quiz_Introduction%20to%20Machine%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ffr08rgWsb_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QUIZ : INTRODUCTION TO MACHINE LEARNING\n",
        "---"
      ],
      "metadata": {
        "id": "i_7u11gQsfm9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TxDBg9yXsrj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. A common split ratio for training, validation, and test sets is\n",
        "1. 50% Training / 25% Validation / 25% Testing\n",
        "2. 60% Training / 20% Validation / 20% Testing\n",
        "3. 80% Training / 10% Validation / 10% Testing\n",
        "4. 90% Training / 5% Validation / 5% Testing"
      ],
      "metadata": {
        "id": "5FDmOFWJssUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **It depends on the dataset size and the specific problem**, but among the options given, **Option 3: 80% Training / 10% Validation / 10% Testing** is the most commonly used **default split** in many machine learning tasks.\n",
        "\n",
        "Here's a breakdown of the reasoning behind each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **50% Training / 25% Validation / 25% Testing**\n",
        "\n",
        "* ✅ More balanced across all sets.\n",
        "* ❌ **Not ideal for small datasets** — too little data left for training, which can harm model performance.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **60% Training / 20% Validation / 20% Testing**\n",
        "\n",
        "* ✅ Better training size than Option 1.\n",
        "* ❌ Still relatively small training portion compared to validation/test.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **80% Training / 10% Validation / 10% Testing** ✅ **(Most Common)**\n",
        "\n",
        "* ✅ Strong training set size.\n",
        "* ✅ Sufficient validation and test sizes for tuning and evaluation.\n",
        "* ✅ Common in deep learning and large dataset scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **90% Training / 5% Validation / 5% Testing**\n",
        "\n",
        "* ✅ Best when you have **very large datasets**, where even 5% holds enough data for validation and testing.\n",
        "* ❌ Risky for small datasets — validation/test may be too small to provide reliable results.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary:\n",
        "\n",
        "| Option | Use Case                                         | Commonality   |\n",
        "| ------ | ------------------------------------------------ | ------------- |\n",
        "| 1      | Rare; maybe in research where equal split needed | ❌ Uncommon    |\n",
        "| 2      | Slightly better, but still uncommon              | ❌ Less common |\n",
        "| 3      | Balanced; good for most tasks                    | ✅ Most common |\n",
        "| 4      | For very large datasets                          | ✅ Situational |\n",
        "\n",
        "Let me know your dataset size or problem type, and I can recommend a more tailored split ratio.\n"
      ],
      "metadata": {
        "id": "t6tYwxFKs6Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrG_rAOws9bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Which of the following startegies can help reduce variance in a model?\n",
        "1. Increasing model complexity\n",
        "2. Adding more features\n",
        "3. Regularization techniques\n",
        "4. Ignoring the validation set"
      ],
      "metadata": {
        "id": "9KYmHohEs91x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Regularization techniques**\n",
        "\n",
        "---\n",
        "\n",
        "### Let’s break down each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Increasing model complexity**\n",
        "\n",
        "* ❌ **Increases variance**\n",
        "* More complex models (e.g., deeper trees, more parameters) can overfit the training data, leading to higher variance and poor generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Adding more features**\n",
        "\n",
        "* ❌ Can **increase variance** (especially irrelevant or noisy features)\n",
        "* May help only if the features are **useful and informative** — otherwise, the model might overfit.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Regularization techniques**\n",
        "\n",
        "* ✅ **Correct**\n",
        "* Techniques like **L1 (Lasso)**, **L2 (Ridge)**, or **Dropout (in neural nets)** reduce variance by penalizing model complexity, helping to prevent overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Ignoring the validation set**\n",
        "\n",
        "* ❌ **Increases the risk of overfitting**\n",
        "* Without a validation set, you can’t properly tune hyperparameters or detect overfitting, which can lead to higher variance.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Regularization techniques**\n"
      ],
      "metadata": {
        "id": "JeINLCLxtGDt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxz2qxk1tI39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3. High Bias in a model typically results in\n",
        "1. Overfitting\n",
        "2. Underfitting\n",
        "3. High Variance\n",
        "4. Good generalization"
      ],
      "metadata": {
        "id": "5gQuIZ85tJLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Underfitting**\n",
        "\n",
        "---\n",
        "\n",
        "### Here's what each option means in the context of **high bias**:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Overfitting**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* Overfitting is typically caused by **low bias** and **high variance**, where the model is too complex and learns noise in the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Underfitting**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* High bias means the model is **too simple** to capture the underlying patterns in the data, resulting in poor performance on both training and test sets — classic underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **High Variance**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* High variance is the opposite of high bias — it happens when a model is too flexible and sensitive to training data.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Good generalization**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* High bias typically results in **poor generalization** because the model fails to learn from the training data effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Underfitting**\n"
      ],
      "metadata": {
        "id": "UVOnxImPtPqD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7nC_iEftSH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. What is overfitting in a machine learning model?\n",
        "1. When the model performs poorly on both training and test data\n",
        "2. When the model learns noise from the training data\n",
        "3. When the model is too simple to capture the underlying patterns\n",
        "4. When the model generalizes well to new data"
      ],
      "metadata": {
        "id": "T6s0ZxaltScK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. When the model learns noise from the training data**\n",
        "\n",
        "---\n",
        "\n",
        "### Let’s go over each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **When the model performs poorly on both training and test data**\n",
        "\n",
        "* ❌ **Describes underfitting**, not overfitting.\n",
        "* In overfitting, the model performs **well on training** but **poorly on test** data.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **When the model learns noise from the training data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Overfitting happens when a model **memorizes training data**, including noise or random fluctuations, which harms its ability to generalize to unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **When the model is too simple to capture the underlying patterns**\n",
        "\n",
        "* ❌ **Describes high bias / underfitting.**\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **When the model generalizes well to new data**\n",
        "\n",
        "* ❌ That’s actually the **goal** — not a definition of overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. When the model learns noise from the training data**\n"
      ],
      "metadata": {
        "id": "j3EA6SW9tZWA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caaO0vM0tb6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. What is the purpose of splitting a dataset into training, validation, and test sets?\n",
        "1. To increase the size of the dataset\n",
        "2. To ensure the model generalizes well to unseen data\n",
        "3. To reduce the complexity of the model\n",
        "4. To eliminate noise from the data"
      ],
      "metadata": {
        "id": "w8xg3nRNtcXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. To ensure the model generalizes well to unseen data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **To increase the size of the dataset**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* Splitting a dataset **divides** it — it does **not** increase its size.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **To ensure the model generalizes well to unseen data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* The **training set** is used to learn the model.\n",
        "* The **validation set** is used for tuning hyperparameters.\n",
        "* The **test set** is used to evaluate final performance on unseen data — this checks how well the model generalizes.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **To reduce the complexity of the model**\n",
        "\n",
        "* ❌ Not directly related.\n",
        "* Model complexity is controlled by design choices and regularization, not data splitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **To eliminate noise from the data**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* Noise reduction is done through preprocessing, filtering, or robust modeling — not by splitting the data.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. To ensure the model generalizes well to unseen data**\n"
      ],
      "metadata": {
        "id": "61ayr-watiqr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0onidP3Otk9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. In which type of learning does the model try to find patterns in unlabeled data?\n",
        "1. Supervised Learning\n",
        "2. Unsupervised Learning\n",
        "3. Reinforcement Learning\n",
        "4. Semi-Supervised Learning"
      ],
      "metadata": {
        "id": "9psvrUeOtlNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Unsupervised Learning**\n",
        "\n",
        "---\n",
        "\n",
        "### Here's a breakdown of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Supervised Learning**\n",
        "\n",
        "* ❌ Involves **labeled data** (input-output pairs).\n",
        "* The model learns to map inputs to known outputs.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Unsupervised Learning**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* The model works with **unlabeled data** and tries to find hidden patterns, such as **clustering** or **dimensionality reduction**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Reinforcement Learning**\n",
        "\n",
        "* ❌ Involves learning through **rewards and penalties** in an environment — not purely about labeled or unlabeled data.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Semi-Supervised Learning**\n",
        "\n",
        "* ❌ Uses **a mix of labeled and unlabeled data** — not just unlabeled.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Unsupervised Learning**\n"
      ],
      "metadata": {
        "id": "o4IIAwfctrlr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvz0L4I9tuHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7. Which type of machine learning invloves training on labeled data?\n",
        "1. Supervised learning\n",
        "2. Unsupervised Learning\n",
        "3. Reinforcement learning\n",
        "4. Semi-Supervised Learning"
      ],
      "metadata": {
        "id": "fuowAFm4tui-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **1. Supervised Learning**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Supervised Learning**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Involves **training on labeled data** — the model learns to map inputs to known outputs (e.g., classification, regression).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Unsupervised Learning**\n",
        "\n",
        "* ❌ Uses **unlabeled data** — the goal is to find structure or patterns (e.g., clustering, dimensionality reduction).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Reinforcement Learning**\n",
        "\n",
        "* ❌ Involves learning from **interactions with an environment** using rewards/punishments — not labeled datasets.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Semi-Supervised Learning**\n",
        "\n",
        "* ❌ Uses a **combination of labeled and unlabeled data**, not exclusively labeled data.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **1. Supervised Learning**\n"
      ],
      "metadata": {
        "id": "nPIJQpZ0t2hg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FVP9TXOyt4tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8. The Bias-Variance Tradeoff is about\n",
        "1. Balancing the complexity of the model to avoid both underfitting and overfitting\n",
        "2. Increasing model complexity to reduce bias\n",
        "3. Using only validation data to tune the model's hyperparameters\n",
        "4. Selecting between supervised and unsupervised learning techniques"
      ],
      "metadata": {
        "id": "KDD947Mct5HC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **1. Balancing the complexity of the model to avoid both underfitting and overfitting**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Balancing the complexity of the model to avoid both underfitting and overfitting**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* The **Bias-Variance Tradeoff** is about finding a model that's **complex enough** to capture patterns (low bias) but **not so complex** that it overfits the noise (low variance).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Increasing model complexity to reduce bias**\n",
        "\n",
        "* ❌ Partially true, but **incomplete and misleading**.\n",
        "* Increasing complexity **does reduce bias**, but it can **increase variance**, which is why a balance is needed — hence the tradeoff.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Using only validation data to tune the model's hyperparameters**\n",
        "\n",
        "* ❌ While validation data **is used for tuning**, this is **not what the Bias-Variance Tradeoff refers to**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Selecting between supervised and unsupervised learning techniques**\n",
        "\n",
        "* ❌ Completely unrelated to the bias-variance tradeoff.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **1. Balancing the complexity of the model to avoid both underfitting and overfitting**\n"
      ],
      "metadata": {
        "id": "gngeW2BMuAaS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1PHpm8euDys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9. High variance in a model leads to\n",
        "1. Consistent performance with different training data\n",
        "2. Poor performance on both training and test data\n",
        "3. Excellent performance on training data but poor generalization to new data\n",
        "4. Low bias and good generalization to unseen data\n",
        "\n"
      ],
      "metadata": {
        "id": "2D786XE2uDR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Excellent performance on training data but poor generalization to new data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Consistent performance with different training data**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* High variance means the model is **sensitive to changes in training data**, leading to **inconsistent performance**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Poor performance on both training and test data**\n",
        "\n",
        "* ❌ Describes **high bias / underfitting**, not high variance.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Excellent performance on training data but poor generalization to new data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* High variance models **overfit** the training data, capturing noise and patterns too precisely, which leads to **poor performance on unseen/test data**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Low bias and good generalization to unseen data**\n",
        "\n",
        "* ❌ Low bias is true, but **high variance harms generalization**, not improves it.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Excellent performance on training data but poor generalization to new data**\n"
      ],
      "metadata": {
        "id": "bkxAczlcuN3A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "67x9HW_XuPG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10. High bias in a model suggests that the model is\n",
        "1. Too complex and overfits the data\n",
        "2. Too simple and under fits the data\n",
        "3. Consistent in its performance with different training data\n",
        "4. Able to capture complex patterns well"
      ],
      "metadata": {
        "id": "qg_hsTWBuPjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Too simple and underfits the data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Too complex and overfits the data**\n",
        "\n",
        "* ❌ Incorrect.\n",
        "* That describes a model with **low bias and high variance**, not **high bias**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Too simple and under fits the data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* High bias means the model makes **strong assumptions** and **oversimplifies** the problem, leading to **underfitting** — it fails to capture important patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Consistent in its performance with different training data**\n",
        "\n",
        "* ✅ This is a **trait of high bias**, but it's **not the main issue** — the question is asking **what high bias suggests about the model**, and that is that it's **too simple**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Able to capture complex patterns well**\n",
        "\n",
        "* ❌ Opposite of high bias — that would describe a **low-bias, complex model**.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Too simple and under fits the data**\n"
      ],
      "metadata": {
        "id": "IbuOOYfvuYKf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uDEr8WkuanG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11. Regularization helps prevent overfitting by\n",
        "1. Engineering new features to improve model performance\n",
        "2. Making the model simpler and less prone to memorizing the training data\n",
        "3. Increasing the training time to allow the model to learn more complex patterns\n",
        "4. Validating the model's performance using cross-validation techniques"
      ],
      "metadata": {
        "id": "UfB4azACubGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Making the model simpler and less prone to memorizing the training data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Engineering new features to improve model performance**\n",
        "\n",
        "* ❌ Feature engineering helps improve model input but is **not regularization**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Making the model simpler and less prone to memorizing the training data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Regularization techniques like **L1, L2**, or **Dropout** add penalties to complex models, encouraging simpler models that generalize better and reduce overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Increasing the training time to allow the model to learn more complex patterns**\n",
        "\n",
        "* ❌ More training time can sometimes lead to **overfitting**, not prevent it.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Validating the model's performance using cross-validation techniques**\n",
        "\n",
        "* ❌ Cross-validation helps estimate performance reliably but **is not a regularization method**.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Making the model simpler and less prone to memorizing the training data**\n"
      ],
      "metadata": {
        "id": "VdSu0YvFuifO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qeDI4Ywculj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12. Underfitting is indicated by\n",
        "1. High accuracy on training data and low accuracy on test data\n",
        "2. Poor performance on both training and test data due to an overly simple model\n",
        "3. A large difference between training and validation error rates\n",
        "4. High variance in the model's predictions"
      ],
      "metadata": {
        "id": "-pZ2lAb5umEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Poor performance on both training and test data due to an overly simple model**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **High accuracy on training data and low accuracy on test data**\n",
        "\n",
        "* ❌ This indicates **overfitting**, not underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Poor performance on both training and test data due to an overly simple model**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Underfitting happens when the model is too simple to capture underlying patterns, resulting in **bad performance everywhere**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **A large difference between training and validation error rates**\n",
        "\n",
        "* ❌ This usually signals **overfitting**, where the model fits training data well but generalizes poorly.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **High variance in the model's predictions**\n",
        "\n",
        "* ❌ High variance is related to **overfitting**, not underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Poor performance on both training and test data due to an overly simple model**\n"
      ],
      "metadata": {
        "id": "PKh2ldxFuuaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzLCcR1Oux7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13. Overfitting occurs when a model\n",
        "1. Performs poorly on both training and test data\n",
        "2. learns the training data too well, including noise and details\n",
        "3. Has a high bias and fails to capture the underlying patterns\n",
        "4. Exhibits low variance and consistent performance"
      ],
      "metadata": {
        "id": "qYBQ48yIuycD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. learns the training data too well, including noise and details**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Performs poorly on both training and test data**\n",
        "\n",
        "* ❌ This describes **underfitting**, not overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Learns the training data too well, including noise and details**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Overfitting means the model captures not just the true patterns but also the noise, leading to poor generalization on new data.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Has a high bias and fails to capture the underlying patterns**\n",
        "\n",
        "* ❌ High bias relates to **underfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Exhibits low variance and consistent performance**\n",
        "\n",
        "* ❌ Overfitting usually causes **high variance**, not low.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. learns the training data too well, including noise and details**\n"
      ],
      "metadata": {
        "id": "D1aW2BwHu7LO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAeVcTS8u99k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14. The primary objective of a machine learning model is to\n",
        "1. Explicitly program every action\n",
        "2. Learn from data and make accurate predictions\n",
        "3. Permanently store large amounts of data\n",
        "4. Manually classify data into categories"
      ],
      "metadata": {
        "id": "JfFvEzslu-b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Learn from data and make accurate predictions**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Explicitly program every action**\n",
        "\n",
        "* ❌ This describes traditional programming, not machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Learn from data and make accurate predictions**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Machine learning models aim to **automatically learn patterns from data** and apply that knowledge to predict outcomes on new data.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Permanently store large amounts of data**\n",
        "\n",
        "* ❌ Data storage is not the main goal of machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Manually classify data into categories**\n",
        "\n",
        "* ❌ Manual classification is done by humans, not by the model itself.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Learn from data and make accurate predictions**\n"
      ],
      "metadata": {
        "id": "pm73rSXlvFam"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKepioB2vIPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q15. K-Ford Cross-Validation helps ensure that the model\n",
        "1. Learns faster by reducing training time\n",
        "2. Generalizes well to unseen data\n",
        "3. Becomes more complex to capture intricate patterns\n",
        "4. Processes the data more efficiently"
      ],
      "metadata": {
        "id": "PWRtrMv0vIzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Generalizes well to unseen data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Learns faster by reducing training time**\n",
        "\n",
        "* ❌ K-Fold Cross-Validation actually increases training time since the model is trained multiple times on different folds.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Generalizes well to unseen data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* K-Fold Cross-Validation splits the data into multiple training and validation sets, helping assess model performance more reliably and reducing overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Becomes more complex to capture intricate patterns**\n",
        "\n",
        "* ❌ Model complexity is controlled by the model design and hyperparameters, not by cross-validation.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Processes the data more efficiently**\n",
        "\n",
        "* ❌ Cross-validation doesn’t speed up data processing; it’s focused on evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Generalizes well to unseen data**\n"
      ],
      "metadata": {
        "id": "YPPI9yM_vQdM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeQEPtg9vTBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q16. The primary purpose of the validation set in data splitting is to\n",
        "1. Train the model on the data\n",
        "2. Evaluate teh final performance of the trained model\n",
        "3. Fine-tune and optimize the model's hyperparameters\n",
        "4. Store the model's learned parameters for future use"
      ],
      "metadata": {
        "id": "Qr14nulmvTSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Fine-tune and optimize the model's hyperparameters**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Train the model on the data**\n",
        "\n",
        "* ❌ The training set is used for training, not the validation set.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Evaluate the final performance of the trained model**\n",
        "\n",
        "* ❌ The **test set** is used for final evaluation, not the validation set.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Fine-tune and optimize the model's hyperparameters**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* The validation set is used during training to **tune hyperparameters** and **make decisions** about model architecture or early stopping.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Store the model's learned parameters for future use**\n",
        "\n",
        "* ❌ This is related to model saving/checkpointing, not the role of the validation set.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Fine-tune and optimize the model's hyperparameters**\n"
      ],
      "metadata": {
        "id": "KrPQcgePvbLf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBEdn9AVvdiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q17. Semi-supervised learning combines\n",
        "1. Pre-trained models with new data\n",
        "2. Reinforcement signals with the learning process\n",
        "3. A small amount of labeled data with a large amount of unlabeled data\n",
        "4. High-dimensional features to improve model performance"
      ],
      "metadata": {
        "id": "s9ZmsoWYvd3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. A small amount of labeled data with a large amount of unlabeled data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Pre-trained models with new data**\n",
        "\n",
        "* ❌ This refers to **transfer learning**, not semi-supervised learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Reinforcement signals with the learning process**\n",
        "\n",
        "* ❌ This describes **reinforcement learning**, not semi-supervised learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **A small amount of labeled data with a large amount of unlabeled data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Semi-supervised learning leverages both labeled and unlabeled data to improve learning when labeled data is scarce.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **High-dimensional features to improve model performance**\n",
        "\n",
        "* ❌ This refers to feature engineering or dimensionality techniques, not semi-supervised learning.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. A small amount of labeled data with a large amount of unlabeled data**\n"
      ],
      "metadata": {
        "id": "tLyfykdOvlij"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDTHr1K8voPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q18. In unsupervised learning, Principal Component Analysis (PCA) is commonly used for\n",
        "1. Clustering data into groups\n",
        "2. Reducing the dimensionality of the data\n",
        "3. Learning from rewards and punishments\n",
        "4. Training the model on labeled data"
      ],
      "metadata": {
        "id": "1jLwYLPavon3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Reducing the dimensionality of the data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Clustering data into groups**\n",
        "\n",
        "* ❌ Clustering is a different technique (e.g., K-Means), not PCA.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Reducing the dimensionality of the data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* PCA transforms the data into a lower-dimensional space by finding directions (principal components) that capture the most variance.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Learning from rewards and punishments**\n",
        "\n",
        "* ❌ This describes reinforcement learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Training the model on labeled data**\n",
        "\n",
        "* ❌ PCA is unsupervised and does not require labeled data.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Reducing the dimensionality of the data**\n"
      ],
      "metadata": {
        "id": "JqU76S97vy50"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgzn2jNgv2NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q19. Reinforcement learning involves an agent learning through interactions with its environment to\n",
        "1. Classify data into predefined categories\n",
        "2. Identify hidden patterns in unlabeled data\n",
        "3. Maximize rewards and minimize penalties\n",
        "4. Combine labeled and unlabeled data"
      ],
      "metadata": {
        "id": "dcAlX-NTv23s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Maximize rewards and minimize penalties**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Classify data into predefined categories**\n",
        "\n",
        "* ❌ This is typical of **supervised learning**, not reinforcement learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Identify hidden patterns in unlabeled data**\n",
        "\n",
        "* ❌ This describes **unsupervised learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Maximize rewards and minimize penalties**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Reinforcement learning trains an agent to take actions in an environment to maximize cumulative rewards and avoid penalties.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Combine labeled and unlabeled data**\n",
        "\n",
        "* ❌ This refers to **semi-supervised learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Maximize rewards and minimize penalties**\n"
      ],
      "metadata": {
        "id": "4NcovdPBv_Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhV_u6opwB9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q20. Which of the following is a key charcteristic of a feature in machine learning?\n",
        "1. The final output generated by the model\n",
        "2. A measurable property or charcteristic of the data\n",
        "3. The data used to test the model's performance\n",
        "4. The process of learning from the data itself"
      ],
      "metadata": {
        "id": "2vQBOv9gwCVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. A measurable property or characteristic of the data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **The final output generated by the model**\n",
        "\n",
        "* ❌ This is the **prediction or label**, not a feature.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **A measurable property or characteristic of the data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Features are individual measurable attributes or variables used as input for the model.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **The data used to test the model's performance**\n",
        "\n",
        "* ❌ This refers to the **test set**, not features.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **The process of learning from the data itself**\n",
        "\n",
        "* ❌ This describes **training or learning**, not features.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. A measurable property or characteristic of the data**\n"
      ],
      "metadata": {
        "id": "Hkj_sRyWwKIT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gs3NW3__wMv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q21. In supervised learning, the model is trained on\n",
        "1. Unlabeled data without any guidance\n",
        "2. Rewards and punishments from the environment\n",
        "3. Labeled data with known inputs and outputs\n",
        "4. Patterns identifies without any feedbacks"
      ],
      "metadata": {
        "id": "mIu-q1rswNLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Labeled data with known inputs and outputs**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Unlabeled data without any guidance**\n",
        "\n",
        "* ❌ This describes **unsupervised learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Rewards and punishments from the environment**\n",
        "\n",
        "* ❌ This is **reinforcement learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Labeled data with known inputs and outputs**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* In supervised learning, the model learns from data where both the inputs and the corresponding correct outputs (labels) are provided.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Patterns identified without any feedbacks**\n",
        "\n",
        "* ❌ This again refers to **unsupervised learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Labeled data with known inputs and outputs**\n"
      ],
      "metadata": {
        "id": "o9bxSSiOwUD-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMwEwDEqwWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q22. What is the primary goal of reinforcement learning?\n",
        "1. To classify data into categories\n",
        "2. To learn from rewards and penalties\n",
        "3. To analyze large datasets\n",
        "4. To predict future outcomes"
      ],
      "metadata": {
        "id": "OopUDGEHwW84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. To learn from rewards and penalties**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **To classify data into categories**\n",
        "\n",
        "* ❌ This is typical of **supervised learning**, not reinforcement learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **To learn from rewards and penalties**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Reinforcement learning involves an agent learning to make decisions by receiving feedback in the form of rewards or penalties from its environment.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **To analyze large datasets**\n",
        "\n",
        "* ❌ While data analysis can be part of many ML tasks, it's not the primary goal of reinforcement learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **To predict future outcomes**\n",
        "\n",
        "* ❌ This is more aligned with supervised learning or time series forecasting.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. To learn from rewards and penalties**\n"
      ],
      "metadata": {
        "id": "2At8BrptwgC3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDIBZKBswif5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q23. Which of the following is typically used for evaluating the final performance of a model?\n",
        "1. Training Set\n",
        "2. Validation Set\n",
        "3. Test Set\n",
        "4. None of the ablove"
      ],
      "metadata": {
        "id": "V4Sz4u7nwjA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **3. Test Set**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Training Set**\n",
        "\n",
        "* ❌ Used to train the model, **not** for final evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Validation Set**\n",
        "\n",
        "* ❌ Used for tuning hyperparameters and model selection, **not** for final performance evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Test Set**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* The test set is held out from training and validation to provide an **unbiased evaluation** of the final model's performance on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **None of the above**\n",
        "\n",
        "* ❌ Since the test set is the correct answer, this is incorrect.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **3. Test Set**\n"
      ],
      "metadata": {
        "id": "I83FvWNpwvw2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6QlQbAAwxJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q24. Which of the following indicates underfitting?\n",
        "1. High accuracy on training data and low accuracy on test data\n",
        "2. Low accuracy on both training and test data  \n",
        "3. Large difference between training and validation error rates\n",
        "4. High vaiance in model predictions"
      ],
      "metadata": {
        "id": "4m_zikK5wxjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. Low accuracy on both training and test data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **High accuracy on training data and low accuracy on test data**\n",
        "\n",
        "* ❌ This indicates **overfitting**, not underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Low accuracy on both training and test data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* Underfitting happens when the model is too simple to capture the underlying patterns, resulting in poor performance on both training and test data.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Large difference between training and validation error rates**\n",
        "\n",
        "* ❌ Usually indicates **overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **High variance in model predictions**\n",
        "\n",
        "* ❌ High variance is associated with overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. Low accuracy on both training and test data**\n"
      ],
      "metadata": {
        "id": "jfO2eYqQw7Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGnD3v-sw9nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q25. High variance in a model indicates\n",
        "1. The model is too simple\n",
        "2. The model captures noise in the training data\n",
        "3. The model is well-optimized\n",
        "4. The model has low bias"
      ],
      "metadata": {
        "id": "yAAczbgww-IU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is: **2. The model captures noise in the training data**\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of each option:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **The model is too simple**\n",
        "\n",
        "* ❌ This describes **high bias** or underfitting, not high variance.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **The model captures noise in the training data**\n",
        "\n",
        "* ✅ **Correct.**\n",
        "* High variance means the model is too sensitive to training data, including noise, leading to overfitting and poor generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **The model is well-optimized**\n",
        "\n",
        "* ❌ High variance typically means the model is **overfitting**, so it’s not well-optimized.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **The model has low bias**\n",
        "\n",
        "* ❌ While high variance often comes with low bias, the key issue with high variance is **overfitting**, not just bias level.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Answer:\n",
        "\n",
        "> ✅ **2. The model captures noise in the training data**\n"
      ],
      "metadata": {
        "id": "bnhKTRHdxG7e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R50JErjXxOGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tt4ItqslxO2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14GiojUhxOnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJ7JcGk1xOam"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}